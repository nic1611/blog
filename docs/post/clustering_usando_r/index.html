<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Clustering usando R | Q.G do Tux</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="O objetivo do clustering é o de realizar o agrupamento de entidades/exemplos de um conjunto de dados (as linhas de uma matriz ou dataframe) com base na similaridade entre estes">
    <meta name="generator" content="Hugo 0.82.0" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    

  
  
    <link rel="stylesheet" href="/blog/ananke/dist/main.css_5c99d70a7725bacd4c701e995b969fea.css" >
  




    
      
<link rel="shortcut icon" href="/blog/images/favicon.svg" type="image/x-icon" />


    

    
    
    <meta property="og:title" content="Clustering usando R" />
<meta property="og:description" content="O objetivo do clustering é o de realizar o agrupamento de entidades/exemplos de um conjunto de dados (as linhas de uma matriz ou dataframe) com base na similaridade entre estes" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://nic1611.github.io/blog/post/clustering_usando_r/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-09-12T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2021-09-12T00:00:00&#43;00:00" /><meta property="og:site_name" content="Q.G do Tux" />

<meta itemprop="name" content="Clustering usando R">
<meta itemprop="description" content="O objetivo do clustering é o de realizar o agrupamento de entidades/exemplos de um conjunto de dados (as linhas de uma matriz ou dataframe) com base na similaridade entre estes"><meta itemprop="datePublished" content="2021-09-12T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2021-09-12T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="1377">
<meta itemprop="keywords" content="r,analise de dados," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Clustering usando R"/>
<meta name="twitter:description" content="O objetivo do clustering é o de realizar o agrupamento de entidades/exemplos de um conjunto de dados (as linhas de uma matriz ou dataframe) com base na similaridade entre estes"/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  
  
  <header class="cover bg-top" style="background-image: url('https://images.unsplash.com/photo-1489875347897-49f64b51c1f8?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&amp;ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1050&amp;q=80');">
    <div class="pb3-m pb6-l bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/blog/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Q.G do Tux
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/blog/post/" title="Artigos page">
              Artigos
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/blog/tags/" title="Tags page">
              Tags
            </a>
          </li>
          
        </ul>
      
      







<a href="https://www.linkedin.com/in/nicolas-soffi-565028198/" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="https://github.com/nic1611" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>








    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          <h1 class="f2 f1-l fw2 white-90 mb0 lh-title">Clustering usando R</h1>
          
            <h2 class="fw1 f5 f3-l white-80 measure-wide-l center lh-copy mt3 mb4">
              O objetivo do clustering é o de realizar o agrupamento de entidades/exemplos de um conjunto de dados (as linhas de uma matriz ou dataframe) com base na similaridade entre estes
            </h2>
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        ARTIGOS
      </aside>
      




  <div id="sharing" class="mt3">

    
    <a href="https://www.facebook.com/sharer.php?u=https://nic1611.github.io/blog/post/clustering_usando_r/" class="facebook no-underline" aria-label="share on Facebook">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765,50.32h6.744V33.998h4.499l0.596-5.624h-5.095  l0.007-2.816c0-1.466,0.14-2.253,2.244-2.253h2.812V17.68h-4.5c-5.405,0-7.307,2.729-7.307,7.317v3.377h-3.369v5.625h3.369V50.32z   M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>

    </a>

    
    
    <a href="https://twitter.com/share?url=https://nic1611.github.io/blog/post/clustering_usando_r/&amp;text=Clustering%20usando%20R" class="twitter no-underline" aria-label="share on Twitter">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

    </a>

    
    <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://nic1611.github.io/blog/post/clustering_usando_r/&amp;title=Clustering%20usando%20R" class="linkedin no-underline" aria-label="share on LinkedIn">
      <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

    </a>
  </div>


      <h1 class="f1 athelas mt3 mb1">Clustering usando R</h1>
      
      <p class="tracked">
          By <strong>
          
              Nicolas Soffi
          
          </strong>
      </p>
      
      
      <time class="f6 mv4 dib tracked" datetime="2021-09-12T00:00:00Z">September 12, 2021</time>

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><h1 id="clustering">Clustering</h1>
<h2 id="introdução">Introdução</h2>
<p>O objetivo do clustering é o de realizar o agrupamento de entidades / exemplos de um conjunto de dados (as linhas de uma matriz ou dataframe) com base na similaridade entre estes. Uma tarefa similar passa pelo agrupamento das colunas (variáveis). 
Embora não se pretenda neste texto abordar em detalhe as variantes, as formulações e os algoritmos para realizar esta tarefa note-se que as abordagens para este problemas variam sobretudo nas métricas usadas com vista à definição de similaridade, nos algoritmos usados para realizar o agrupamento, na forma que assume a saída destes mesmos algoritmos e, finalmente, na forma de visualizar e interpretar os resultados. 
Neste texto, abordaremos duas abordagens distintas, o clustering hierárquico e o clustering k-means, focando na forma como estas se podem implementar com a linguagem R.</p>
<h2 id="clustering-hierárquico">Clustering hierárquico</h2>
<p>O clustering hierárquico tem como principal característica o tipo de resultados 
que gera que está intimamente ligado com o processo usado na sua construção. Neste caso, o resultado final do processo é uma árvore binária que representa possíveis divisões dos dados em clusters. Assim, na raiz todos os dados estão agrupados num único cluster, e ao descer na árvore os clusters vão-se dividindo de forma binária, ou seja, em cada nó da árvore são criados dois clusters pela divisão de um único. 
O método mais usado para construir estas árvores é designado por 
aglomerativo, pois inicia-se com um cluster para cada exemplo, ou seja parte das folhas da árvore em direção à raiz, no processo de construção. Em cada iteração, vão-se juntando dois clusters e criando um único (criando nós na árvore) até se atingir o ponto em que todos os clusters estão unidos num único (raiz da árvore). 
O processo é baseado numa matriz de distâncias onde estão guardadas as distâncias entre todos os pares de objetos; esta matriz é construída aplicando uma métrica de similaridade sobre as linhas da matriz inicial de dados. Esta pode ser, por exemplo, baseada em métricas clássicas de distância como a distância euclidiana ou a distância de Manhattan ou, em alternativa, métricas baseadas na correlação (e.g. Spearman ou Pearson. 
Para obter uma matriz de distâncias em R, pode usar-se a função dist. Esta 
recebe como argumento uma matriz ou um data frame com valores numéricos, retornando a matriz de distâncias. Por omissão, o método usado para o cálculo das distâncias é a distância euclidiana, mas podem ser escolhidas outras opções como a distância de Manhattan ou a distãncia de Minkowski, através da definição do argumento method. 
O exemplo seguinte mostra como se pode calcular a matriz de distâncias para 
um exemplo com pontos gerados de forma aleatória formando três clusters naturais. Note que o resultado é uma matriz triangular dado que as matrizes de distâncias são simétricas.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-R" data-lang="R">x <span style="color:#f92672">=</span> <span style="color:#a6e22e">rnorm</span>(<span style="color:#ae81ff">12</span>,mean<span style="color:#f92672">=</span><span style="color:#a6e22e">rep</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#ae81ff">3</span>,each<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>),sd<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>) 
y <span style="color:#f92672">=</span> <span style="color:#a6e22e">rnorm</span>(<span style="color:#ae81ff">12</span>,mean<span style="color:#f92672">=</span><span style="color:#a6e22e">rep</span>(<span style="color:#a6e22e">c</span>(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">1</span>),each<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>),sd<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>) 
dataFrame <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">data.frame</span>(x<span style="color:#f92672">=</span>x,y<span style="color:#f92672">=</span>y) 
<span style="color:#a6e22e">dist</span>(dataFrame)
</code></pre></div><pre><code>            1          2          3          4          5          6          7
2  0.20642068                                                                  
3  0.33061879 0.22807374                                                       
4  0.75146312 0.57341611 0.70477161                                            
5  1.69987967 1.52512599 1.37926316 1.42841505                                 
6  1.85433604 1.65480425 1.57319004 1.36853928 0.52512738                      
7  1.27469223 1.07041532 1.02321407 0.77194462 0.71838837 0.60479049           
8  1.43718223 1.24621901 1.13810773 1.07359908 0.36994125 0.45862069 0.34949609
9  2.00937781 1.91775057 1.69807147 2.10964406 1.02696006 1.54643980 1.61521290
10 2.10039289 1.99127326 1.77936524 2.12754673 0.92259869 1.42499933 1.56849129
11 1.96897529 1.87760174 1.65778939 2.07220004 1.00661024 1.52805954 1.58463720
12 1.75644918 1.67883553 1.45467613 1.92125873 1.02643369 1.55000062 1.51113162
            8          9         10         11
2                                             
3                                             
4                                             
5                                             
6                                             
7                                             
8                                             
9  1.30271310                                 
10 1.23685031 0.21110702                      
11 1.27525702 0.04040931 0.23045445           
12 1.23396283 0.28163120 0.45936467 0.24501607
</code></pre>
<p>Para executar o processo de clustering hierárquico usa-se a função hclust. Esta 
recebe como argumento a matriz com as distâncias. Como argumento opcional (method), a função permite escolher a forma como se calculam distâncias entre clusters com mais do que um ponto nos passos intermédios do algoritmo. Os valores possíveis para esta opção incluem “complete” (valor por omissão, indica que a distância entre 2 clusters é a maior distância entre qualquer par de elementos dos 2 clusters), “single” (indica que a distância entre 2 clusters é a menor distância entre qualquer par de elementos dos 2 clusters) e “average” (indica que a distância entre 2 clusters é a média das distância entre todos os pares de elementos dos 2 clusters). 
Veja-se um exemplo de aplicação da função hclust com os dados do exemplo 
anterior:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-R" data-lang="R">distxy <span style="color:#f92672">=</span> <span style="color:#a6e22e">dist</span>(dataFrame, method <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;euclidean&#34;</span>) 
hc <span style="color:#f92672">=</span> <span style="color:#a6e22e">hclust</span>(distxy) 
<span style="color:#a6e22e">plot</span>(hc)
</code></pre></div><p><img src="output_3_0.png" alt="png"></p>
<p>Para ilustrar estes métodos com um exemplo usando um conjunto de dados de 
maior dimensão, tome-se como ponto de partida os dados do conjunto de dados iris ja usados em capítulos anteriores. No exemplo seguinte, os dados são inicialmente standardizados para que a métrica de distância pese de forma uniforme as várias variáveis, podendo visualizar-se o efeito com um gráfico do tipo boxplot. Note-se que o atributo Species (posição 5) não é utilizado neste processo, sendo usados apenas os atributos numéricos.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-R" data-lang="R">iris.sc <span style="color:#f92672">=</span> <span style="color:#a6e22e">scale</span>(iris[,<span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#ae81ff">4</span>])
<span style="color:#a6e22e">boxplot</span>(iris[,<span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#ae81ff">4</span>]) 
<span style="color:#a6e22e">boxplot</span>(iris.sc)
</code></pre></div><p><img src="output_5_0.png" alt="png"></p>
<p><img src="output_5_1.png" alt="png"></p>
<p>Em seguida, procede-se ao cálculo da matriz de distâncias usando distâncias 
euclideanas e realiza-se o processo de clustering hierárquico usando a funçãoo hclust.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-R" data-lang="R">dist.iris <span style="color:#f92672">=</span> <span style="color:#a6e22e">dist</span>(iris.sc, method <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;euclidean&#34;</span>) 
hc.complete <span style="color:#f92672">=</span> <span style="color:#a6e22e">hclust</span>(dist.iris, method <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;complete&#34;</span>) 
<span style="color:#a6e22e">plot</span>(hc.complete, cex <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.4</span>)
</code></pre></div><p><img src="output_7_0.png" alt="png"></p>
<p>No gráfico gerado pelo código anterior, note-se que o número de pontos torna o 
resultado difícil de interpretar. Em muitos casos, faz sentido comparar a divisão dos dados em clusters com conhecimento próprio do problema. Neste caso, iremos usar o campo iris$Species como divisão natural dos dados (note-se que este campo não foi usado para realizar o clustering). O exemplo seguinte usa este campo para colocar as folhas da árvore e, assim, verificar os clusters gerados com os clusters naturais, usando dois valores distintos para o argumento method na função hclust.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-R" data-lang="R">my.plot.hc <span style="color:#f92672">=</span> <span style="color:#a6e22e">function</span>(hclust, lab <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#a6e22e">length</span>(hclust<span style="color:#f92672">$</span>order),  
                      lab.col<span style="color:#f92672">=</span><span style="color:#a6e22e">rep</span>(<span style="color:#ae81ff">1</span>, <span style="color:#a6e22e">length</span>(hclust<span style="color:#f92672">$</span>order)), hang <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.1</span>, <span style="color:#66d9ef">...</span>) 
{ 
  y <span style="color:#f92672">=</span> <span style="color:#a6e22e">rep</span>(hclust<span style="color:#f92672">$</span>height, <span style="color:#ae81ff">2</span>) 
  x <span style="color:#f92672">=</span> <span style="color:#a6e22e">as.numeric</span>(hclust<span style="color:#f92672">$</span>merge) 
  y <span style="color:#f92672">=</span> y<span style="color:#a6e22e">[which</span>(x<span style="color:#f92672">&lt;</span><span style="color:#ae81ff">0</span>)] 
  x <span style="color:#f92672">=</span> x<span style="color:#a6e22e">[which</span>(x<span style="color:#f92672">&lt;</span><span style="color:#ae81ff">0</span>)] 
  x <span style="color:#f92672">=</span> <span style="color:#a6e22e">abs</span>(x) 
  y <span style="color:#f92672">=</span> y<span style="color:#a6e22e">[order</span>(x)] 
  x <span style="color:#f92672">=</span> x<span style="color:#a6e22e">[order</span>(x)] 
  <span style="color:#a6e22e">plot</span>(hclust, labels <span style="color:#f92672">=</span> F, hang <span style="color:#f92672">=</span> hang, <span style="color:#66d9ef">...</span>) 
  <span style="color:#a6e22e">text</span>(x <span style="color:#f92672">=</span> x, y <span style="color:#f92672">=</span> y[hclust<span style="color:#f92672">$</span>order]<span style="color:#f92672">-</span> (<span style="color:#a6e22e">max</span>(hclust<span style="color:#f92672">$</span>height) <span style="color:#f92672">*</span> hang),  
       labels <span style="color:#f92672">=</span> lab[hclust<span style="color:#f92672">$</span>order], col <span style="color:#f92672">=</span> lab.col[hclust<span style="color:#f92672">$</span>order], srt <span style="color:#f92672">=</span> <span style="color:#ae81ff">90</span>,  
       adj <span style="color:#f92672">=</span> <span style="color:#a6e22e">c</span>(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">0.5</span>), xpd <span style="color:#f92672">=</span> <span style="color:#66d9ef">NA</span>, <span style="color:#66d9ef">...</span>) 
}

dist.iris <span style="color:#f92672">=</span> <span style="color:#a6e22e">dist</span>(iris.sc, method <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;euclidean&#34;</span>) 
hc.complete <span style="color:#f92672">=</span> <span style="color:#a6e22e">hclust</span>(dist.iris, method <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;complete&#34;</span>) 
<span style="color:#a6e22e">my.plot.hc</span>(hc.complete,lab.col<span style="color:#f92672">=</span><span style="color:#a6e22e">as.integer</span>(iris<span style="color:#f92672">$</span>Species)<span style="color:#ae81ff">+1</span>, cex<span style="color:#f92672">=</span><span style="color:#ae81ff">0.4</span>)
hc.average <span style="color:#f92672">=</span> <span style="color:#a6e22e">hclust</span>(dist.iris, method <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;average&#34;</span>) 
<span style="color:#a6e22e">my.plot.hc</span>(hc.average,lab.col<span style="color:#f92672">=</span><span style="color:#a6e22e">as.integer</span>(iris<span style="color:#f92672">$</span>Species)<span style="color:#ae81ff">+1</span>,cex<span style="color:#f92672">=</span><span style="color:#ae81ff">0.4</span>)
</code></pre></div><p><img src="output_9_0.png" alt="png"></p>
<p><img src="output_9_1.png" alt="png"></p>
<p>Uma representação gráfica dos dados relacionada com o clustering hierárquico 
são os heatmaps, que podem ser construídos em R com a função heatmap. Esta permite representar os dados como uma imagem onde cada valor da matriz de dados é representado com uma célula cuja cor varia consoante o valor respetivo, num gradiente de cores que pode ser configurado. Os heatmaps tipicamente incluem as árvores criadas por clustering hierárquico quer ao nível das linhas, quer ao nível das colunas de dados. Note o exemplo seguinte:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-R" data-lang="R">x1 <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">rnorm</span>(<span style="color:#ae81ff">12</span>,mean<span style="color:#f92672">=</span><span style="color:#a6e22e">rep</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#ae81ff">3</span>,each<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>),sd<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>) 
x2 <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">rnorm</span>(<span style="color:#ae81ff">12</span>,mean<span style="color:#f92672">=</span><span style="color:#a6e22e">rep</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#ae81ff">3</span>,each<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>),sd<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>) 
y1 <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">rnorm</span>(<span style="color:#ae81ff">12</span>,mean<span style="color:#f92672">=</span><span style="color:#a6e22e">rep</span>(<span style="color:#a6e22e">c</span>(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">1</span>),each<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>),sd<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>) 
y2 <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">rnorm</span>(<span style="color:#ae81ff">12</span>,mean<span style="color:#f92672">=</span><span style="color:#a6e22e">rep</span>(<span style="color:#a6e22e">c</span>(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">1</span>),each<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>),sd<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>) 
df2 <span style="color:#f92672">=</span> <span style="color:#a6e22e">data.frame</span>(x1, x2, y1, y2) 
<span style="color:#a6e22e">heatmap</span>(<span style="color:#a6e22e">as.matrix</span>(df2))
</code></pre></div><p><img src="output_11_0.png" alt="png"></p>
<h2 id="clustering-k-means">Clustering k-means</h2>
<p>O problema de clustering k-means constitui uma das possíveis formulações do clustering, onde o objetivo é o de minimizar a média do quadrado das distâncias de cada ponto ao centro do cluster a que pertence. Nesta formulação, o número de clusters é dado como parâmetro de entrada (designado por k). Dado que este problema apresenta uma significativa complexidade (dentro da classe dos problemas NP-completos), métodos heurísticos são tipicamente usados na resolução do problema. 
A função kmeans permite resolver um problema de clustering k-means dado um 
conjunto de dados e o valor de k (parâmetro centers).<br>
Veja um exemplo de seguida, usando os dados criados na secção anterior:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-R" data-lang="R">resKmeans <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">kmeans</span>(dataFrame, centers<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>) 
resKmeans<span style="color:#f92672">$</span>cluster 
<span style="color:#a6e22e">plot</span>(dataFrame<span style="color:#f92672">$</span>x,dataFrame<span style="color:#f92672">$</span>y, col<span style="color:#f92672">=</span>resKmeans<span style="color:#f92672">$</span>cluster, pch<span style="color:#f92672">=</span><span style="color:#ae81ff">19</span>, cex<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>) 
<span style="color:#a6e22e">points</span>(resKmeans<span style="color:#f92672">$</span>centers, col<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#ae81ff">3</span>, pch<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, cex<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, lwd<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>) 
</code></pre></div><ol class=list-inline>
	<li>3</li>
	<li>3</li>
	<li>3</li>
	<li>3</li>
	<li>1</li>
	<li>1</li>
	<li>1</li>
	<li>1</li>
	<li>2</li>
	<li>2</li>
	<li>2</li>
	<li>2</li>
</ol>
<p><img src="output_13_1.png" alt="png"></p>
<p>Note-se que, em casos reais, dado que o método de otimização usado é heurístico 
há a necessidade de se correr o algoritmo por diversas vezes, de forma a aumentar a qualidade da solução final encontrada. Este número de repetições pode ser controlado pelo parâmetro nstart. 
De forma idêntica ao método anterior, ir-se-á demonstrar este método usando o 
conjunto de dados iris.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-R" data-lang="R">kmeans.iris <span style="color:#f92672">=</span> <span style="color:#a6e22e">kmeans</span>(iris[,<span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#ae81ff">4</span>], centers <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>, nstart <span style="color:#f92672">=</span> <span style="color:#ae81ff">10000</span>) 
<span style="color:#a6e22e">table</span>(kmeans.iris<span style="color:#f92672">$</span>cluster, iris<span style="color:#f92672">$</span>Species)
</code></pre></div><pre><code>    setosa versicolor virginica
  1     50          0         0
  2      0         48        14
  3      0          2        36
</code></pre>
<p>Note-se que o segundo comando executado permite comparar o resultado da função kmeans com o agrupamento natural dos dados pelo campo Species. Esta comparação permite aferir da conformidade dos clusters gerados e dos clusters naturais.</p>
<ul class="pa0">
  
   <li class="list">
     <a href="/blog/tags/r" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">r</a>
   </li>
  
   <li class="list">
     <a href="/blog/tags/analise-de-dados" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">analise de dados</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      <div id="disqus_thread"></div>
<script>
    

    

    (function() { 
    var d = document, s = d.createElement('script');
    s.src = 'https://qg-tux.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3">Relacionado</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="/blog/post/reducao_de_dimencionalidade/">Redução de Dimensionalidade usando R</a>
        </li>
	    
    </ul>
</div>

</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://nic1611.github.io/blog/" >
    &copy;  Q.G do Tux 2022 
  </a>
    <div>







<a href="https://www.linkedin.com/in/nicolas-soffi-565028198/" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="https://github.com/nic1611" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>







</div>
  </div>
</footer>

  </body>
</html>
